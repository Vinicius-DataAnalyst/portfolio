{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinicius-DataAnalyst/portfolio/blob/main/12_PROJ_FacialRecog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1WxD1GSWsDiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-deps torch torchvision facenet-pytorch --quiet\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "irytrx9DiJzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsAddSsEgn47",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Carrega um classificador prÃ©-treinado para rostos\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Carrega uma imagem\n",
        "uploaded_img_path = '/content/drive/MyDrive/01.FIAP_GraduacÌ§aÌƒo/2025/FASE06_trabalho/img_rosto.jpg'\n",
        "img = cv2.imread(uploaded_img_path)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Detecta rostos\n",
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "# Desenha retÃ¢ngulos nos rostos\n",
        "for (x, y, w, h) in faces:\n",
        "    # Increased thickness to 5 and changed color to green (0, 255, 0)\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
        "\n",
        "# Mostra o resultado - Redimensiona a imagem antes de mostrar\n",
        "resized_img = cv2.resize(img, (int(img.shape[1] * 0.1), int(img.shape[0] * 0.1))) # Reduz para 10%\n",
        "cv2_imshow(resized_img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Caminhos\n",
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'\n",
        "\n",
        "# GPU se disponÃ­vel\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Usando device:\", device)\n",
        "\n",
        "# Modelos\n",
        "mtcnn = MTCNN(image_size=160, margin=0, keep_all=False, device=device)\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "def gerar_embedding(img_path):\n",
        "    try:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "    except:\n",
        "        print(f\"Erro ao abrir {img_path}\")\n",
        "        return None\n",
        "    face = mtcnn(img)\n",
        "    if face is None:\n",
        "        print(f\"Nenhum rosto detectado em {img_path}\")\n",
        "        return None\n",
        "    face = face.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        emb = resnet(face)\n",
        "    return emb.cpu().numpy().flatten()\n",
        "\n",
        "# Gera mÃ©dia dos embeddings de treino\n",
        "print(\"ðŸ”¹ Gerando embeddings mÃ©dios de treino...\")\n",
        "embeddings_treino = {}\n",
        "for pessoa in os.listdir(train_dir):\n",
        "    pasta = os.path.join(train_dir, pessoa)\n",
        "    if not os.path.isdir(pasta):\n",
        "        continue\n",
        "    embs = []\n",
        "    for img_name in os.listdir(pasta):\n",
        "        img_path = os.path.join(pasta, img_name)\n",
        "        emb = gerar_embedding(img_path)\n",
        "        if emb is not None:\n",
        "            embs.append(emb)\n",
        "    if embs:\n",
        "        embeddings_treino[pessoa] = np.mean(embs, axis=0)\n",
        "        print(f\"{pessoa}: {len(embs)} imagens processadas\")\n",
        "\n",
        "# LÃª as imagens na pasta Test\n",
        "print(\"\\nðŸ”¹ Testando imagens individuais...\")\n",
        "for img_name in os.listdir(test_dir):\n",
        "    img_path = os.path.join(test_dir, img_name)\n",
        "    if not os.path.isfile(img_path):\n",
        "        continue\n",
        "\n",
        "    emb_teste = gerar_embedding(img_path)\n",
        "    if emb_teste is None:\n",
        "        continue\n",
        "\n",
        "    # Calcula similaridade de cosseno com todos os embeddings mÃ©dios\n",
        "    similaridades = {\n",
        "        nome: cosine_similarity([emb_teste], [emb_ref])[0][0]\n",
        "        for nome, emb_ref in embeddings_treino.items()\n",
        "    }\n",
        "\n",
        "    reconhecido = max(similaridades, key=similaridades.get)\n",
        "    confianca = similaridades[reconhecido]\n",
        "\n",
        "    print(f\"Arquivo: {img_name:20s} | Previsto: {reconhecido:12s} | Similaridade: {confianca:.3f}\")\n"
      ],
      "metadata": {
        "id": "LDays3lWlzI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7caSw-lBrd-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}